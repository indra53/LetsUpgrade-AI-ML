{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project objective "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-Build classification model using Logistic Regression and KNN for diabities dataset and try to predict based on feature if \n",
    "  person have diabities or not\n",
    "\n",
    "2-Try to improve performance with ensemble technique and compare if it work tha base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('diabetes_with_names.csv') # 0 mean- no and 1 mean yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()\n",
    "data.fillna(0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data in X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.iloc[:,:-1]\n",
    "y=data.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a model using Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INDRAJEET YADAV\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\INDRAJEET YADAV\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=log_reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7857142857142857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84       100\n",
      "           1       0.72      0.63      0.67        54\n",
      "\n",
      "    accuracy                           0.79       154\n",
      "   macro avg       0.77      0.75      0.76       154\n",
      "weighted avg       0.78      0.79      0.78       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,ypred))\n",
    "# model is good as 78%\n",
    "\n",
    "print(classification_report(y_test,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# so our model accuracy is 78% lets creat KNN model and check what happen for same dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model=KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INDRAJEET YADAV\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_knn=knn_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7532467532467533\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,ypred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       100\n",
      "           1       0.67      0.57      0.62        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.71      0.72       154\n",
      "weighted avg       0.75      0.75      0.75       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,ypred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# so our accuracy score at this time is 75 % let try to improve model using Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Bagging classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgcl_log=BaggingClassifier(base_estimator=log_reg,n_estimators=12) # log_reg is the base model applied above and n_estimator \n",
    "#you can dicide based on how much leg u want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if testing score is more than training score that mean model has been overfited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INDRAJEET YADAV\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\INDRAJEET YADAV\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\INDRAJEET YADAV\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\INDRAJEET YADAV\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\INDRAJEET YADAV\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\INDRAJEET YADAV\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\INDRAJEET YADAV\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\INDRAJEET YADAV\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\INDRAJEET YADAV\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\INDRAJEET YADAV\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\INDRAJEET YADAV\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\INDRAJEET YADAV\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\INDRAJEET YADAV\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "bgcl_log.fit(x_train,y_train)\n",
    "bgcl_log_ypred=bgcl_log.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bgcl Testing score 0.7922077922077922\n"
     ]
    }
   ],
   "source": [
    "# print('bgcl Training score',bgcl_log.score(x_train,y_train)) # to check training score \n",
    "\n",
    "print('bgcl Testing score',bgcl_log.score(x_test,y_test)) # to check testing score\n",
    "\n",
    "# as below we can see Training score is 77 and testing score is 79 that is good fit of model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BGCL acc 0.7922077922077922\n"
     ]
    }
   ],
   "source": [
    "print('BGCL acc',accuracy_score(y_test,bgcl_log_ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We find there is no Improvement even using  Ensemble Bagging model on Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now lets checkout other Ensembling technique if improve our model accuracy or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier(n_estimators=8,max_depth=5,max_features=6,random_state=2,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INDRAJEET YADAV\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 8\n",
      "building tree 2 of 8\n",
      "building tree 3 of 8\n",
      "building tree 4 of 8\n",
      "building tree 5 of 8\n",
      "building tree 6 of 8\n",
      "building tree 7 of 8\n",
      "building tree 8 of 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5, max_features=6, n_estimators=8,\n",
       "                       random_state=2, verbose=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "rf_yp=rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy 0.7987012987012987\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Accuracy',accuracy_score(rf_yp,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now lets check with other method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Trees Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "et=ExtraTreesClassifier(n_estimators=8,max_depth=7,max_features=7,random_state=2,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 8\n",
      "building tree 2 of 8\n",
      "building tree 3 of 8\n",
      "building tree 4 of 8\n",
      "building tree 5 of 8\n",
      "building tree 6 of 8\n",
      "building tree 7 of 8\n",
      "building tree 8 of 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INDRAJEET YADAV\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(max_depth=7, max_features=7, n_estimators=8,\n",
       "                     random_state=2, verbose=2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "et_ypred=et.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees accuracy 0.7857142857142857\n"
     ]
    }
   ],
   "source": [
    "print('Extra Trees accuracy',accuracy_score(et_ypred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfiting & Underfiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest- Training score 0.8534201954397395\n",
      "Random forest - Testin score 0.7987012987012987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "print('Random forest- Training score', rf.score(x_train,y_train))\n",
    "print('Random forest - Testin score',rf.score(x_test,y_test))\n",
    "\n",
    "#this is overfited model since Training has 85 score and testing have 79 score,\n",
    "\n",
    "#reason- Huge variance , lots of outliers in datasets,unbalance dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets check reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Outcome'].value_counts() # see data is not balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1dc0cb45320>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(data['Outcome'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOOSTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ada boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada=AdaBoostClassifier(base_estimator=log_reg,n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INDRAJEET YADAV\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\INDRAJEET YADAV\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "ada.fit(x_train,y_train)\n",
    "ada_ypred=et.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada_score 0.7857142857142857\n",
      "base_model_score 0.7857142857142857\n"
     ]
    }
   ],
   "source": [
    "print('ada_score',accuracy_score(y_test,ada_ypred))\n",
    "\n",
    "print('base_model_score',accuracy_score(y_test,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see after multiple uses of boosting and bagging model haa same score this might be due to-\n",
    "\n",
    "1- High variance in dataset\n",
    "2- missing datasets or not correct dataset provided\n",
    "\n",
    "hence before create model we must look inside the dataset atleast variance, distribution of data, missing values,model requirement, overfiting model, underfitting model etc\n",
    "\n",
    "However model has perform 80% accurate with Random forest Ensemble mehod which is good for satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
